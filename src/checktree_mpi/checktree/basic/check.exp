###########################################################################
#
#  Copyright 2025 HPC-Gridware GmbH
#
#  Licensed under the Apache License, Version 2.0 (the "License");
#  you may not use this file except in compliance with the License.
#  You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing, software
#  distributed under the License is distributed on an "AS IS" BASIS,
#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#  See the License for the specific language governing permissions and
#  limitations under the License.
#
###########################################################################
#___INFO__MARK_END_NEW__

# define global variable in this namespace
global check_name
global check_category
global check_description
global check_needs
global check_functions
global check_root_access_needs
global check_need_running_system
global check_version_range

#set check_root_access_needs "yes"
#set check_need_running_system "no"
set check_version_range "9.0.5 9.1.0"

# define test's name and run level descriptions
set check_name            "mpi_basic"
set check_category        "MPI PARALLEL VERIFIED"
set check_description(0)  "test basic functionality of the MPI tight integration with the latest version of the first configured MPI installation"
set check_description(100)  "test basic functionality of the MPI tight integration with the latest version of all configured MPI installations"
set check_description(200)  "test basic functionality of the MPI tight integration with all versions of all configured MPI installations"

# define test's dependencies
set check_needs           "init_core_system"

# setup and cleanup functions
set check_setup_function mpi_basic_setup
set check_setup_level_function mpi_basic_setup_level
set check_cleanup_level_function mpi_basic_cleanup_level
set check_cleanup_function mpi_basic_cleanup

# define test's procedure order
set check_functions {}
lappend check_functions "mpi_basic_functional"
lappend check_functions "mpi_basic_restart"

# -------- local test procedures: initialization------------------------------

proc mpi_basic_setup {} {
   get_current_cluster_config_array ts_config
   global mpi_basic_backup mpi_basic_global_conf

   # make sure accounting records are written quickly
   get_config mpi_basic_global_conf
   set conf(reporting_params) [add_or_replace_param $mpi_basic_global_conf(reporting_params) "accounting_flush_time" "accounting_flush_time=0"]
   set_config conf
   # we will create parallel environments and checkpointing environents during the test
   # backup the current list
   get_pe_list mpi_basic_backup(pe_list)
   get_ckpt_list mpi_basic_backup(ckpt_list)

   # create a test queue
   # @todo CS-1157 can be reproduced by setting slots to 4
   set q(slots) 8
   add_queue "mpi.q" "@allhosts" q

   # create the example's checkpointing environment and add it to the queue
   mpi_configure_ckpt
}

proc mpi_basic_setup_level {} {
   global CHECK_ACT_LEVEL
   global mpi_basic_mpi_list

   if {$CHECK_ACT_LEVEL == 0} {
      set mpi_basic_mpi_list [lindex [config_mpi_get_mpi_list] 0]
   } else {
      set mpi_basic_mpi_list [config_mpi_get_mpi_list]
   }
#   set mpi_basic_mpi_list "openmpi"
}

proc mpi_basic_cleanup_level {} {
   global CHECK_ACT_LEVEL
}

proc mpi_basic_cleanup {} {
   get_current_cluster_config_array ts_config
   global mpi_basic_backup mpi_basic_global_conf
   global mpi_basic_mpi_list

   delete_all_jobs
   wait_for_end_of_all_jobs

   del_queue "mpi.q" "" 1 1

   get_pe_list pe_list
   foreach pe $pe_list {
      if {[lsearch -exact $mpi_basic_backup(pe_list) $pe] == -1} {
         # this PE was created during the test
         ts_log_fine "deleting PE $pe"
         del_pe $pe
      }
   }

   get_ckpt_list ckpt_list
   foreach ckpt $ckpt_list {
      if {[lsearch -exact $mpi_basic_backup(ckpt_list) $ckpt] == -1} {
         # this CKPT was created during the test
         ts_log_fine "deleting CKPT $ckpt"
         del_ckpt $ckpt
      }
   }

   reset_config mpi_basic_global_conf

   unset -nocomplain mpi_basic_backup mpi_basic_global_conf mpi_basic_mpi_list
}

proc mpi_basic_run_job {mpi version arch dir with_reschedule} {
   get_current_cluster_config_array ts_config
   global CHECK_USER

   set ret 1

   set job_script "$ts_config(testsuite_root_dir)/checktree_mpi/checktree/job.sh"
   set mpi_binary "./testmpi-$arch"
   set work_total 120
   set template [config_mpi_get_mpi_template $mpi]

   # select a master host having one of the given architectures
   set master_host [host_conf_get_suited_hosts 1 {} $arch]

   # build job options
   set base_dir [config_mpi_get_mpi_install_dir]
   set master_arch [resolve_arch $master_host]
   set install_dir "$base_dir/$mpi-$version/$master_arch"
   set output_file "testmpi.out"
   set job_opts "-cwd -o $output_file -j y -cwd -v MPIR_HOME=$install_dir"
   if {$with_reschedule} {
      append job_opts " -ckpt testmpi.ckpt"
   }
   append job_opts " -pe $template.pe 8 -l a='$arch'"
   append job_opts " -scope master -l h=$master_host"
   set job_args "$job_script $mpi_binary -o testmpi.csv $work_total"

   # create the output file and tail -f to it
   start_remote_prog $master_host $CHECK_USER "touch" "$dir/$output_file"
   set id [open_remote_spawn_process $master_host $CHECK_USER "tail" "-f $dir/$output_file"]
   if {$id == ""} {
      set ret 0
   }

   if {$ret} {
      # submit the job
      ts_log_fine "submitting job with options $job_opts"
      set job_id [submit_job "$job_opts $job_args" 1 60 "" "" $dir 1 "qsub" 0]
      if {$job_id <= 0} {
         set ret 0
      } else {
         ts_log_fine "job id $job_id"
         set ret $job_id
      }
   }

   if {$ret} {
      set spawn_id [lindex $id 1]
      set timeout 60
      set done 0
      set rescheduled 0
      expect {
         full_buffer {
            ts_log_severe "full buffer: $expect_out(buffer)"
            set ret 0
         }
         eof {
            ts_log_severe "eof"
            set ret 0
         }
         timeout {
            ts_log_severe "timeout"
            set ret 0
         }
         "\r * done" {
            foreach line [split $expect_out(buffer) "\r"] {
               #ts_log_fine "output with CR: $line"
               if {[string first " done" $line] > 0} {
                  set work_done [lindex [string trim $line] 0]
                  ts_log_fine "$work_done:$work_total work_packages done"
                  if {$work_done > 30 && $with_reschedule && !$rescheduled} {
                     # reschedule the job
                     ts_log_fine "checkpoint and restart job"
                     start_sge_bin "qmod" "-s $job_id"
                     set rescheduled 1
                  }
               }
            }
            exp_continue
         }
         "?*\n" {
            foreach line [split $expect_out(buffer) "\n"] {
               ts_log_fine "output with NL: $line"
               switch -glob $line {
                  "testmpi finished *" {
                     ts_log_fine $line
                     if {$with_reschedule} {
                        ts_log_fine "job finished due to rescheduling"
                        set with_reschedule 0
                        # we continue to wait for the job to restart and finish a second time
                     } else {
                        set done 1
                        break
                     }
                  }
               }
            }
            if {!$done} {
               exp_continue
            }
         }
      }
   }

   close_spawn_process $id

   return $ret
}

proc mpi_basic_check_accounting {job_id dir} {
   ts_log_fine "comparing accounting information against info reported in CSV file in $dir"

   set csv_file "$dir/testmpi.csv"

   # read contents of the file to a buffer
   set csv_file [open $csv_file r]
   set csv_buffer [read $csv_file]
   close $csv_file
   puts $csv_buffer

   # parse CSV data
   parse_csv csv_data csv_buffer "," "Rank"

   # get the accounting record of the master task
   get_qacct "$job_id NONE" master_task_acct
   set master_host $master_task_acct(hostname)

   # condense CSV data: Sum up values for ranks being part of the same PE-Task
   set condensed(index) {}
   foreach rank $csv_data(index) {
      set processor $csv_data($rank,Processor)
      if {$processor == $master_host} {
         set processor "master"
      }
      if {[lsearch -exact $condensed(index) $processor] == -1} {
         lappend condensed(index) $processor
         set condensed($processor,maxrss) $csv_data($rank,maxrss)
         set condensed($processor,cpu) [expr $csv_data($rank,stime) + $csv_data($rank,utime)]
      } else {
         set condensed($processor,maxrss) [expr $condensed($processor,maxrss) + $csv_data($rank,maxrss)]
         set condensed($processor,cpu) [expr $condensed($processor,cpu) + $csv_data($rank,stime) + $csv_data($rank,utime)]
      }
   }

   # @todo comparing the usage is really tricky - there are huge deviations
   #       when tasks are forked by a daemon or by the master task
   #       it seems to work fine on Ubuntu, but on CentOS-like OSes memory consumption seems to
   #       be much higher than reported by the tasks themselves
   if {0} {
      set errors {}
      foreach processor $condensed(index) {
         if {$processor == "master"} {
            mpi_basic_compare_usage condensed master_task_acct $processor errors
         } else {
            get_qacct "$job_id $processor" task_acct
            mpi_basic_compare_usage condensed task_acct $processor errors
         }
      }
      if {[llength $errors] > 0} {
         ts_log_severe "accounting information had errors:\n[join $errors "\n"]"
      }
   }
}

proc mpi_basic_compare_usage {usage_var acct_var processor errors_var} {
   upvar $usage_var usage
   upvar $acct_var acct
   upvar $errors_var errors

   set cpu_percent [expr $acct(cpu) * 100 / $usage($processor,cpu)]
   set rss_percent [expr $acct(maxrss) * 100 / ($usage($processor,maxrss) * 1024)]
   ts_log_fine "$processor: cpu    differs by $cpu_percent %"
   ts_log_fine "$processor: maxrss differs by $rss_percent %"

   if {$cpu_percent < 0} {
      lappend errors "$processor: accounting cpu ($acct(cpu)) is lower than usage cpu ($usage($processor,cpu))"
   }
   if {$rss_percent < 0} {
      lappend errors "$processor: accounting maxrss ($acct(maxrss)) is lower than usage maxrss ([expr $usage($processor,maxrss) * 1024])"
   }

   if {$processor == "master"} {
      # the master task might have a bigger deviation as it contains the overhead of
      # the job script and the mpirun itself
      # @todo only when PE master_forks_slaves
      # @todo with PE daemon_forks_slaves the daemon causes the overhead
      set allowed_deviation 500
   } else {
      # the task should not have a big deviation
      set allowed_deviation 110
   }
   if {$cpu_percent > $allowed_deviation} {
      lappend errors "$processor: accounting cpu ($acct(cpu)) shouldn't be that much higher than usage cpu ($usage($processor,cpu))"
   }
# we cannot make good assumptions about the memory usage
#   if {$rss_percent > $allowed_deviation} {
#      lappend errors "$processor: accounting maxrss ($acct(maxrss)) shouldn't be that much higher than usage maxrss ([expr $usage($processor,maxrss) * 1024])"
#   }
}

proc mpi_basic_get_mpi_versions {mpi} {
   global CHECK_ACT_LEVEL

   # sort the versions in dictionary order, so that the latest version is at the end
   set all_versions [lsort -dictionary [config_mpi_get_mpi_versions $mpi]]

   switch $CHECK_ACT_LEVEL {
      0 -
      100 {
         # only the latest version
         set mpi_versions [lindex $all_versions end]
      }
      200 {
         # all versions
         set mpi_versions $all_versions
      }
   }

   return $mpi_versions
}

proc mpi_basic_functional {{with_reschedule 0}} {
   get_current_cluster_config_array ts_config
   global mpi_basic_mpi_list

   ts_log_fine "testing mpi installations $mpi_basic_mpi_list"

   foreach mpi $mpi_basic_mpi_list {
      ts_log_frame
      ts_log_fine "testing $mpi"

      # create the pe and link it to the queue
      if {![mpi_configure_pe $mpi]} {
         continue
      }

      # get the list of versions we want to test
      set mpi_versions [mpi_basic_get_mpi_versions $mpi]

      foreach version $mpi_versions {
         ts_log_frame
         ts_log_fine "testing version $version"

         # figure out available architectures and make sure that the MPI is installed
         # possibly build and install it
         # we need at least 2 hosts per architecture
         set archs [mpi_get_arch_list $mpi 2]
         if {![mpi_check_build $mpi $version $archs]} {
            continue
         }
         # build the example application
         set dir [get_tmp_directory_name]
         file mkdir $dir

         foreach arch $archs {
            if {![mpi_build_example $mpi $version $arch $dir]} {
               continue
            }
         }

         # run the example application
         foreach arch $archs {
            set job_id [mpi_basic_run_job $mpi $version $arch $dir $with_reschedule]
            if {$job_id == 0} {
               # failed
               continue
            }

            # wait for the job to be fully finished (all acct records must have been written)
            wait_for_jobend $job_id "" 10 0 1

            # check accounting
            if {!$with_reschedule} {
               mpi_basic_check_accounting $job_id $dir
            }
         }
      }
   }
}

proc mpi_basic_restart {} {
   mpi_basic_functional 1
}

